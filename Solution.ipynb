{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d99107",
   "metadata": {},
   "source": [
    "# Cherry Blossom Peak Bloom Prediction 2026 — Python Pipeline\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Cherry blossom bloom timing is a sensitive phenological indicator of climate\n",
    "change, yet accurate annual prediction remains difficult because bloom dates\n",
    "emerge from complex, nonlinear interactions among geography, long-term warming\n",
    "trends, and stochastic weather variability.  We present an interpretable\n",
    "two-model ensemble that exploits complementary information scales.\n",
    "\n",
    "**Model A** captures site-specific momentum through a recency-weighted quadratic\n",
    "trend fitted independently to each of the five competition locations (Kyoto,\n",
    "Washington D.C., Liestal, Vancouver, New York City).  Exponential decay\n",
    "weights (half-life ≈ 6 years) let recent climate shifts dominate the local\n",
    "signal while retaining curvature from longer records.\n",
    "\n",
    "**Model B** learns shared cross-site structure via a pooled Gradient Boosting\n",
    "Regressor (Huber loss, 700 estimators, lr = 0.02, max depth = 3) with\n",
    "features for calendar year, latitude, longitude, altitude, per-site observation\n",
    "depth, and data source.  Training data combines competition records with\n",
    "auxiliary series (Japan, MeteoSwiss, South Korea) and both USA-NPN data\n",
    "products for the NYC site.\n",
    "\n",
    "**Ensemble blending** uses inverse-MAE weights from rolling-origin backtesting.\n",
    "**Prediction intervals** use split-conformal 90th-percentile residual quantiles per location.\n",
    "\n",
    "---\n",
    "\n",
    "This notebook builds a competition-oriented ensemble:\n",
    "\n",
    "- **Model A**: location-level recency-weighted trend.\n",
    "- **Model B**: pooled nonlinear regressor using time + geography + all auxiliary data.\n",
    "- **Ensemble**: inverse-MAE blend from rolling-origin backtesting.\n",
    "- **Intervals**: conformal location-wise residual quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0ce4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:38:49.292044Z",
     "iopub.status.busy": "2026-02-21T14:38:49.291906Z",
     "iopub.status.idle": "2026-02-21T14:38:51.288889Z",
     "shell.execute_reply": "2026-02-21T14:38:51.288461Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "np.random.seed(5103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5da3d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:38:51.292995Z",
     "iopub.status.busy": "2026-02-21T14:38:51.292826Z",
     "iopub.status.idle": "2026-02-21T14:38:51.350174Z",
     "shell.execute_reply": "2026-02-21T14:38:51.349882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "01bc9154-b54b-42d6-af1b-e4a3527ea011",
       "rows": [
        [
         "auxiliary",
         "14209"
        ],
        [
         "competition",
         "385"
        ],
        [
         "npn",
         "4"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 3
       }
      },
      "text/plain": [
       "source\n",
       "auxiliary      14209\n",
       "competition      385\n",
       "npn                4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path('.')\n",
    "\n",
    "competition_files = [\n",
    "    ROOT / 'data/kyoto.csv',\n",
    "    ROOT / 'data/washingtondc.csv',\n",
    "    ROOT / 'data/liestal.csv',\n",
    "    ROOT / 'data/vancouver.csv',\n",
    "    ROOT / 'data/nyc.csv',\n",
    "]\n",
    "\n",
    "aux_files = [\n",
    "    ROOT / 'data/japan.csv',\n",
    "    ROOT / 'data/meteoswiss.csv',\n",
    "    ROOT / 'data/south_korea.csv',\n",
    "]\n",
    "\n",
    "def read_bloom_file(path: Path, source: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    return pd.DataFrame({\n",
    "        'source': source,\n",
    "        'location': df['location'].astype(str),\n",
    "        'lat': pd.to_numeric(df['lat'], errors='coerce'),\n",
    "        'long': pd.to_numeric(df['long'], errors='coerce'),\n",
    "        'alt': pd.to_numeric(df['alt'], errors='coerce'),\n",
    "        'year': pd.to_numeric(df['year'], errors='coerce').astype('Int64'),\n",
    "        'bloom_doy': pd.to_numeric(df['bloom_doy'], errors='coerce')\n",
    "    })\n",
    "\n",
    "competition_raw = pd.concat([read_bloom_file(p, 'competition') for p in competition_files], ignore_index=True)\n",
    "aux_raw = pd.concat([read_bloom_file(p, 'auxiliary') for p in aux_files], ignore_index=True)\n",
    "\n",
    "# NYC enrichment from USA-NPN status observations (site 32789, species 228, Open flowers)\n",
    "npn = pd.read_csv(ROOT / 'data/USA-NPN_status_intensity_observations_data.csv')\n",
    "npn = npn[(npn['Site_ID'] == 32789) & (npn['Species_ID'] == 228) & (npn['Phenophase_ID'] == 501)].copy()\n",
    "npn['Observation_Date'] = pd.to_datetime(npn['Observation_Date'], format='%m/%d/%y', errors='coerce')\n",
    "npn['year'] = npn['Observation_Date'].dt.year\n",
    "npn_yes = (\n",
    "    npn[npn['Phenophase_Status'] == 1]\n",
    "    .sort_values('Observation_Date')\n",
    "    .groupby('year', as_index=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "nyc_npn_status = pd.DataFrame({\n",
    "    'source': 'npn',\n",
    "    'location': 'newyorkcity',\n",
    "    'lat': 40.73040,\n",
    "    'long': -73.99809,\n",
    "    'alt': 8.5,\n",
    "    'year': npn_yes['year'].astype('Int64'),\n",
    "    'bloom_doy': pd.to_numeric(npn_yes['Day_of_Year'], errors='coerce')\n",
    "}).dropna(subset=['year', 'bloom_doy'])\n",
    "\n",
    "# Also use USA-NPN individual phenometrics (pre-computed first-flower DOY)\n",
    "pheno = pd.read_csv(ROOT / 'data/USA-NPN_individual_phenometrics_data.csv')\n",
    "pheno = pheno[(pheno['Site_ID'] == 32789) & (pheno['Species_ID'] == 228) & (pheno['Phenophase_ID'] == 501)].copy()\n",
    "nyc_npn_pheno = (\n",
    "    pheno.groupby('First_Yes_Year', as_index=False)['First_Yes_DOY']\n",
    "    .min()\n",
    "    .rename(columns={'First_Yes_Year': 'year', 'First_Yes_DOY': 'bloom_doy'})\n",
    ")\n",
    "nyc_npn_pheno = nyc_npn_pheno[nyc_npn_pheno['bloom_doy'].notna()].copy()\n",
    "nyc_npn_pheno['source'] = 'npn'\n",
    "nyc_npn_pheno['location'] = 'newyorkcity'\n",
    "nyc_npn_pheno['lat'] = 40.73040\n",
    "nyc_npn_pheno['long'] = -73.99809\n",
    "nyc_npn_pheno['alt'] = 8.5\n",
    "nyc_npn_pheno['year'] = nyc_npn_pheno['year'].astype('Int64')\n",
    "\n",
    "# Merge both NPN sources (status takes priority where years overlap)\n",
    "status_years = set(nyc_npn_status['year'].dropna().astype(int))\n",
    "nyc_npn_pheno_new = nyc_npn_pheno[~nyc_npn_pheno['year'].astype(int).isin(status_years)]\n",
    "nyc_npn = pd.concat([nyc_npn_status, nyc_npn_pheno_new], ignore_index=True)\n",
    "\n",
    "existing_nyc_years = set(competition_raw.loc[competition_raw['location'] == 'newyorkcity', 'year'].dropna().astype(int))\n",
    "nyc_npn = nyc_npn[~nyc_npn['year'].astype(int).isin(existing_nyc_years)]\n",
    "\n",
    "competition = pd.concat([competition_raw, nyc_npn], ignore_index=True)\n",
    "all_data = (\n",
    "    pd.concat([competition, aux_raw], ignore_index=True)\n",
    "    .dropna(subset=['year', 'bloom_doy'])\n",
    "    .query('year >= 1880')\n",
    "    .copy()\n",
    ")\n",
    "all_data['year'] = all_data['year'].astype(int)\n",
    "all_data['site_id'] = all_data['source'] + '::' + all_data['location']\n",
    "\n",
    "competition_sites = sorted(competition_raw['location'].unique())\n",
    "target_year = int(competition_raw['year'].max()) + 1\n",
    "\n",
    "all_data.groupby('source').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebbc0247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:38:51.351737Z",
     "iopub.status.busy": "2026-02-21T14:38:51.351639Z",
     "iopub.status.idle": "2026-02-21T14:38:51.357505Z",
     "shell.execute_reply": "2026-02-21T14:38:51.357173Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_features(df: pd.DataFrame, reference_df: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    ref = out if reference_df is None else reference_df\n",
    "    site_obs = ref.groupby('site_id').size().rename('site_obs').reset_index()\n",
    "    out = out.merge(site_obs, on='site_id', how='left')\n",
    "\n",
    "    out['year_c'] = out['year'] - 1950\n",
    "    out['year_c2'] = out['year_c'] ** 2\n",
    "    out['decade'] = (out['year'] // 10) * 10\n",
    "    out['lat_abs'] = out['lat'].abs()\n",
    "    out['alt_log1p'] = np.log1p(np.clip(out['alt'], a_min=0, a_max=None))\n",
    "    out['site_obs'] = out['site_obs'].fillna(1)\n",
    "    return out\n",
    "\n",
    "def build_global_model() -> Pipeline:\n",
    "    num_cols = ['year', 'year_c', 'year_c2', 'lat', 'long', 'alt_log1p', 'site_obs']\n",
    "    cat_cols = ['source']\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', Pipeline([('imputer', SimpleImputer(strategy='median'))]), num_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    )\n",
    "\n",
    "    model = GradientBoostingRegressor(\n",
    "        loss='huber',\n",
    "        n_estimators=700,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=3,\n",
    "        random_state=5103\n",
    "    )\n",
    "\n",
    "    return Pipeline([('pre', pre), ('model', model)])\n",
    "\n",
    "def predict_local_trend(train_comp: pd.DataFrame, new_comp: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for loc in new_comp['location'].unique():\n",
    "        tr = train_comp[train_comp['location'] == loc].sort_values('year').copy()\n",
    "        nd = new_comp[new_comp['location'] == loc].copy()\n",
    "\n",
    "        n = len(tr)\n",
    "        if n >= 4:\n",
    "            w = np.exp(np.arange(-n + 1, 1) / 6.0)\n",
    "            coef = np.polyfit(tr['year'].values, tr['bloom_doy'].values, deg=2, w=w)\n",
    "            pred = np.polyval(coef, nd['year'].values)\n",
    "        elif n >= 2:\n",
    "            coef = np.polyfit(tr['year'].values, tr['bloom_doy'].values, deg=1)\n",
    "            pred = np.polyval(coef, nd['year'].values)\n",
    "        else:\n",
    "            pred = np.repeat(tr['bloom_doy'].mean(), len(nd))\n",
    "\n",
    "        nd['pred_local'] = pred\n",
    "        rows.append(nd[['location', 'year', 'pred_local']])\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e4ec70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:38:51.359105Z",
     "iopub.status.busy": "2026-02-21T14:38:51.358989Z",
     "iopub.status.idle": "2026-02-21T14:39:16.243474Z",
     "shell.execute_reply": "2026-02-21T14:39:16.242547Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local</td>\n",
       "      <td>7.468177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global</td>\n",
       "      <td>5.072221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>5.610119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model       mae\n",
       "0     local  7.468177\n",
       "1    global  5.072221\n",
       "2  ensemble  5.610119"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_start = max(1900, int(competition_raw['year'].min()) + 20)\n",
    "backtest_years = list(range(backtest_start, int(competition_raw['year'].max()) + 1))\n",
    "\n",
    "rolling_rows = []\n",
    "for y in backtest_years:\n",
    "    train_comp = competition[competition['year'] < y].copy()\n",
    "    test_comp = competition_raw[competition_raw['year'] == y].copy()\n",
    "\n",
    "    if test_comp.empty or train_comp['location'].nunique() < len(competition_sites):\n",
    "        continue\n",
    "\n",
    "    train_all = add_features(all_data[all_data['year'] < y].copy())\n",
    "\n",
    "    test_comp['source'] = 'competition'\n",
    "    test_comp['site_id'] = test_comp['source'] + '::' + test_comp['location']\n",
    "    test_feat = add_features(test_comp.copy(), reference_df=train_all)\n",
    "\n",
    "    local_pred = predict_local_trend(train_comp, test_feat)\n",
    "\n",
    "    g_model = build_global_model()\n",
    "    g_model.fit(train_all, train_all['bloom_doy'])\n",
    "    pred_g = g_model.predict(test_feat)\n",
    "\n",
    "    fold = test_feat[['location', 'year', 'bloom_doy']].merge(local_pred, on=['location', 'year'], how='left')\n",
    "    fold['pred_global'] = pred_g\n",
    "    rolling_rows.append(fold)\n",
    "\n",
    "rolling = pd.concat(rolling_rows, ignore_index=True)\n",
    "\n",
    "mae_local = mean_absolute_error(rolling['bloom_doy'], rolling['pred_local'])\n",
    "mae_global = mean_absolute_error(rolling['bloom_doy'], rolling['pred_global'])\n",
    "\n",
    "w_local = (1.0 / mae_local) / ((1.0 / mae_local) + (1.0 / mae_global))\n",
    "w_global = 1.0 - w_local\n",
    "\n",
    "rolling['pred_ensemble'] = w_local * rolling['pred_local'] + w_global * rolling['pred_global']\n",
    "rolling['abs_err'] = (rolling['bloom_doy'] - rolling['pred_ensemble']).abs()\n",
    "\n",
    "site_q90 = rolling.groupby('location', as_index=False)['abs_err'].quantile(0.90).rename(columns={'abs_err': 'q90'})\n",
    "global_q90 = rolling['abs_err'].quantile(0.90)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'model': ['local', 'global', 'ensemble'],\n",
    "    'mae': [\n",
    "        mae_local,\n",
    "        mae_global,\n",
    "        mean_absolute_error(rolling['bloom_doy'], rolling['pred_ensemble'])\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f20b944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:39:16.248533Z",
     "iopub.status.busy": "2026-02-21T14:39:16.248380Z",
     "iopub.status.idle": "2026-02-21T14:39:23.948767Z",
     "shell.execute_reply": "2026-02-21T14:39:23.948390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>prediction</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kyoto</td>\n",
       "      <td>2026</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liestal</td>\n",
       "      <td>2026</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newyorkcity</td>\n",
       "      <td>2026</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vancouver</td>\n",
       "      <td>2026</td>\n",
       "      <td>93</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washingtondc</td>\n",
       "      <td>2026</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  year  prediction  lower  upper\n",
       "2         kyoto  2026          92     83    101\n",
       "0       liestal  2026          87     79     95\n",
       "4   newyorkcity  2026          92     85     99\n",
       "3     vancouver  2026          93     79    107\n",
       "1  washingtondc  2026          84     77     91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = add_features(all_data.copy())\n",
    "train_comp = competition.copy()\n",
    "\n",
    "newdata = (\n",
    "    competition_raw.sort_values('year')\n",
    "    .groupby('location', as_index=False)\n",
    "    .tail(1)[['location', 'lat', 'long', 'alt']]\n",
    "    .copy()\n",
    ")\n",
    "newdata['source'] = 'competition'\n",
    "newdata['year'] = target_year\n",
    "newdata['bloom_doy'] = np.nan\n",
    "newdata['site_id'] = newdata['source'] + '::' + newdata['location']\n",
    "new_feat = add_features(newdata, reference_df=train_all)\n",
    "\n",
    "local_pred = predict_local_trend(train_comp, new_feat)\n",
    "global_model = build_global_model()\n",
    "global_model.fit(train_all, train_all['bloom_doy'])\n",
    "pred_global = global_model.predict(new_feat)\n",
    "\n",
    "final_pred = new_feat[['location', 'year']].merge(local_pred, on=['location', 'year'], how='left')\n",
    "final_pred['pred_global'] = pred_global\n",
    "final_pred['prediction_raw'] = w_local * final_pred['pred_local'] + w_global * final_pred['pred_global']\n",
    "\n",
    "final_pred = final_pred.merge(site_q90, on='location', how='left')\n",
    "final_pred['q90'] = final_pred['q90'].fillna(global_q90)\n",
    "final_pred['prediction'] = np.clip(np.round(final_pred['prediction_raw']), 1, 366).astype(int)\n",
    "final_pred['lower'] = np.clip(np.floor(final_pred['prediction_raw'] - final_pred['q90']), 1, 366).astype(int)\n",
    "final_pred['upper'] = np.clip(np.ceil(final_pred['prediction_raw'] + final_pred['q90']), 1, 366).astype(int)\n",
    "\n",
    "final_pred = final_pred[['location', 'year', 'prediction', 'lower', 'upper']].sort_values('location')\n",
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba6e102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:39:23.950953Z",
     "iopub.status.busy": "2026-02-21T14:39:23.950850Z",
     "iopub.status.idle": "2026-02-21T14:39:23.966247Z",
     "shell.execute_reply": "2026-02-21T14:39:23.966020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>year</th>\n",
       "      <th>prediction</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>predicted_date</th>\n",
       "      <th>lower_date</th>\n",
       "      <th>upper_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kyoto</td>\n",
       "      <td>2026</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "      <td>2026-04-02</td>\n",
       "      <td>2026-03-24</td>\n",
       "      <td>2026-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liestal</td>\n",
       "      <td>2026</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>2026-03-28</td>\n",
       "      <td>2026-03-20</td>\n",
       "      <td>2026-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newyorkcity</td>\n",
       "      <td>2026</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>99</td>\n",
       "      <td>2026-04-02</td>\n",
       "      <td>2026-03-26</td>\n",
       "      <td>2026-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vancouver</td>\n",
       "      <td>2026</td>\n",
       "      <td>93</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "      <td>2026-04-03</td>\n",
       "      <td>2026-03-20</td>\n",
       "      <td>2026-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washingtondc</td>\n",
       "      <td>2026</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "      <td>2026-03-25</td>\n",
       "      <td>2026-03-18</td>\n",
       "      <td>2026-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  year  prediction  lower  upper predicted_date lower_date  \\\n",
       "2         kyoto  2026          92     83    101     2026-04-02 2026-03-24   \n",
       "0       liestal  2026          87     79     95     2026-03-28 2026-03-20   \n",
       "4   newyorkcity  2026          92     85     99     2026-04-02 2026-03-26   \n",
       "3     vancouver  2026          93     79    107     2026-04-03 2026-03-20   \n",
       "1  washingtondc  2026          84     77     91     2026-03-25 2026-03-18   \n",
       "\n",
       "  upper_date  \n",
       "2 2026-04-11  \n",
       "0 2026-04-05  \n",
       "4 2026-04-09  \n",
       "3 2026-04-17  \n",
       "1 2026-04-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doy_to_date(year: int, doy: int) -> pd.Timestamp:\n",
    "    return pd.to_datetime(f'{year}-{doy:03d}', format='%Y-%j', errors='coerce')\n",
    "\n",
    "submission = final_pred.copy()\n",
    "submission['predicted_date'] = [doy_to_date(y, d) for y, d in zip(submission['year'], submission['prediction'])]\n",
    "submission['lower_date'] = [doy_to_date(y, d) for y, d in zip(submission['year'], submission['lower'])]\n",
    "submission['upper_date'] = [doy_to_date(y, d) for y, d in zip(submission['year'], submission['upper'])]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63f8692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-21T14:39:23.967403Z",
     "iopub.status.busy": "2026-02-21T14:39:23.967313Z",
     "iopub.status.idle": "2026-02-21T14:39:23.974342Z",
     "shell.execute_reply": "2026-02-21T14:39:23.974078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>prediction</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kyoto</td>\n",
       "      <td>92</td>\n",
       "      <td>83</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liestal</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newyorkcity</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vancouver</td>\n",
       "      <td>93</td>\n",
       "      <td>79</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washingtondc</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location  prediction  lower  upper\n",
       "2         kyoto          92     83    101\n",
       "0       liestal          87     79     95\n",
       "4   newyorkcity          92     85     99\n",
       "3     vancouver          93     79    107\n",
       "1  washingtondc          84     77     91"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Competition CSV schema\n",
    "submission[['location', 'prediction', 'lower', 'upper']].to_csv('cherry-predictions-python.csv', index=False)\n",
    "submission[['location', 'prediction', 'lower', 'upper']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
